{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 15:32:30.195355: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/alexlee/miniconda3/envs/hkjc-tf/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Text\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pprint\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")\n",
    "\n",
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"timestamp\": x[\"timestamp\"],\n",
    "})\n",
    "movies = movies.map(lambda x: x[\"movie_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec={'movie_title': TensorSpec(shape=(), dtype=tf.string, name=None), 'user_id': TensorSpec(shape=(), dtype=tf.string, name=None), 'timestamp': TensorSpec(shape=(), dtype=tf.int64, name=None), 'user_rating': TensorSpec(shape=(), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join('data','all_races_cleaned.csv'), index_col=0)\n",
    "\n",
    "ratings = pd.DataFrame()\n",
    "ratings['movie_title'] = df['horse_colour'].astype(str)\n",
    "ratings['user_id'] = df['race_class'].astype(str)\n",
    "ratings['timestamp'] = df['horse_weight'].astype('int64')\n",
    "ratings['user_rating'] = df['place'].astype('float32')\n",
    "ratings = tf.data.Dataset.from_tensor_slices(dict(ratings))\n",
    "\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = np.concatenate(list(ratings.map(lambda x: x[\"timestamp\"]).batch(100)))\n",
    "\n",
    "max_timestamp = timestamps.max()\n",
    "min_timestamp = timestamps.min()\n",
    "\n",
    "timestamp_buckets = np.linspace(\n",
    "    min_timestamp, max_timestamp, num=1000,\n",
    ")\n",
    "\n",
    "unique_movie_titles = np.unique(np.concatenate(list(movies.batch(1000))))\n",
    "unique_user_ids = np.unique(np.concatenate(list(ratings.batch(1_000).map(\n",
    "    lambda x: x[\"user_id\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, use_timestamps):\n",
    "    super().__init__()\n",
    "\n",
    "    self._use_timestamps = use_timestamps\n",
    "\n",
    "    self.user_embedding = tf.keras.Sequential([\n",
    "        tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_user_ids, mask_token=None),\n",
    "        tf.keras.layers.Embedding(len(unique_user_ids) + 1, 32),\n",
    "    ])\n",
    "\n",
    "    if use_timestamps:\n",
    "      self.timestamp_embedding = tf.keras.Sequential([\n",
    "          tf.keras.layers.Discretization(timestamp_buckets.tolist()),\n",
    "          tf.keras.layers.Embedding(len(timestamp_buckets) + 1, 32),\n",
    "      ])\n",
    "      self.normalized_timestamp = tf.keras.layers.Normalization(\n",
    "          axis=None\n",
    "      )\n",
    "\n",
    "      self.normalized_timestamp.adapt(timestamps)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    if not self._use_timestamps:\n",
    "      return self.user_embedding(inputs[\"user_id\"])\n",
    "\n",
    "    return tf.concat([\n",
    "        self.user_embedding(inputs[\"user_id\"]),\n",
    "        self.timestamp_embedding(inputs[\"timestamp\"]),\n",
    "        tf.reshape(self.normalized_timestamp(inputs[\"timestamp\"]), (-1, 1)),\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    max_tokens = 10_000\n",
    "\n",
    "    self.title_embedding = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "          vocabulary=unique_movie_titles, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_movie_titles) + 1, 32)\n",
    "    ])\n",
    "\n",
    "    self.title_vectorizer = tf.keras.layers.TextVectorization(\n",
    "        max_tokens=max_tokens)\n",
    "\n",
    "    self.title_text_embedding = tf.keras.Sequential([\n",
    "      self.title_vectorizer,\n",
    "      tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n",
    "      tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    ])\n",
    "\n",
    "    self.title_vectorizer.adapt(movies)\n",
    "\n",
    "  def call(self, titles):\n",
    "    return tf.concat([\n",
    "        self.title_embedding(titles),\n",
    "        self.title_text_embedding(titles),\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovielensModel(tfrs.models.Model):\n",
    "\n",
    "  def __init__(self, use_timestamps):\n",
    "    super().__init__()\n",
    "    self.query_model = tf.keras.Sequential([\n",
    "      UserModel(use_timestamps),\n",
    "      tf.keras.layers.Dense(32)\n",
    "    ])\n",
    "    self.candidate_model = tf.keras.Sequential([\n",
    "      MovieModel(),\n",
    "      tf.keras.layers.Dense(32)\n",
    "    ])\n",
    "    self.task = tfrs.tasks.Retrieval(\n",
    "        metrics=tfrs.metrics.FactorizedTopK(\n",
    "            candidates=movies.batch(128).map(self.candidate_model),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "  def compute_loss(self, features, training=False):\n",
    "    # We only pass the user id and timestamp features into the query model. This\n",
    "    # is to ensure that the training inputs would have the same keys as the\n",
    "    # query inputs. Otherwise the discrepancy in input structure would cause an\n",
    "    # error when loading the query model after saving it.\n",
    "    query_embeddings = self.query_model({\n",
    "        \"user_id\": features[\"user_id\"],\n",
    "        \"timestamp\": features[\"timestamp\"],\n",
    "    })\n",
    "    movie_embeddings = self.candidate_model(features[\"movie_title\"])\n",
    "\n",
    "    return self.task(query_embeddings, movie_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "split = 0.8\n",
    "\n",
    "train = shuffled.take(int(split * len(shuffled)))\n",
    "test = shuffled.skip(int(split * len(shuffled))).take(int((1-split) * len(shuffled)))\n",
    "\n",
    "cached_train = train.shuffle(100).batch(2048)\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "9/9 [==============================] - 3s 150ms/step - factorized_top_k/top_1_categorical_accuracy: 0.2354 - factorized_top_k/top_5_categorical_accuracy: 0.2371 - factorized_top_k/top_10_categorical_accuracy: 0.2774 - factorized_top_k/top_50_categorical_accuracy: 0.2796 - factorized_top_k/top_100_categorical_accuracy: 0.2805 - loss: 14379.5846 - regularization_loss: 0.0000e+00 - total_loss: 14379.5846\n",
      "Epoch 2/3\n",
      "9/9 [==============================] - 1s 151ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0604 - factorized_top_k/top_5_categorical_accuracy: 0.0650 - factorized_top_k/top_10_categorical_accuracy: 0.0650 - factorized_top_k/top_50_categorical_accuracy: 0.0698 - factorized_top_k/top_100_categorical_accuracy: 0.0742 - loss: 14208.7047 - regularization_loss: 0.0000e+00 - total_loss: 14208.7047\n",
      "Epoch 3/3\n",
      "9/9 [==============================] - 1s 152ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0235 - factorized_top_k/top_5_categorical_accuracy: 0.0271 - factorized_top_k/top_10_categorical_accuracy: 0.0310 - factorized_top_k/top_50_categorical_accuracy: 0.0929 - factorized_top_k/top_100_categorical_accuracy: 0.1000 - loss: 14207.8062 - regularization_loss: 0.0000e+00 - total_loss: 14207.8062\n",
      "9/9 [==============================] - 2s 151ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0142 - factorized_top_k/top_5_categorical_accuracy: 0.0147 - factorized_top_k/top_10_categorical_accuracy: 0.0160 - factorized_top_k/top_50_categorical_accuracy: 0.1016 - factorized_top_k/top_100_categorical_accuracy: 0.1038 - loss: 14207.0211 - regularization_loss: 0.0000e+00 - total_loss: 14207.0211\n",
      "2/2 [==============================] - 0s 111ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0111 - factorized_top_k/top_5_categorical_accuracy: 0.0111 - factorized_top_k/top_10_categorical_accuracy: 0.0134 - factorized_top_k/top_50_categorical_accuracy: 0.0955 - factorized_top_k/top_100_categorical_accuracy: 0.0978 - loss: 12505.8381 - regularization_loss: 0.0000e+00 - total_loss: 12505.8381\n",
      "Top-100 accuracy (train): 0.10.\n",
      "Top-100 accuracy (test): 0.10.\n"
     ]
    }
   ],
   "source": [
    "model = MovielensModel(use_timestamps=False)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "model.fit(cached_train, epochs=3)\n",
    "\n",
    "train_accuracy = model.evaluate(\n",
    "    cached_train, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "test_accuracy = model.evaluate(\n",
    "    cached_test, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "\n",
    "print(f\"Top-100 accuracy (train): {train_accuracy:.2f}.\")\n",
    "print(f\"Top-100 accuracy (test): {test_accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "9/9 [==============================] - 3s 166ms/step - factorized_top_k/top_1_categorical_accuracy: 0.2983 - factorized_top_k/top_5_categorical_accuracy: 0.3623 - factorized_top_k/top_10_categorical_accuracy: 0.3693 - factorized_top_k/top_50_categorical_accuracy: 0.3857 - factorized_top_k/top_100_categorical_accuracy: 0.3952 - loss: 14462.2150 - regularization_loss: 0.0000e+00 - total_loss: 14462.2150\n",
      "Epoch 2/3\n",
      "9/9 [==============================] - 2s 168ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1711 - factorized_top_k/top_5_categorical_accuracy: 0.3963 - factorized_top_k/top_10_categorical_accuracy: 0.4220 - factorized_top_k/top_50_categorical_accuracy: 0.4875 - factorized_top_k/top_100_categorical_accuracy: 0.5182 - loss: 14203.7730 - regularization_loss: 0.0000e+00 - total_loss: 14203.7730\n",
      "Epoch 3/3\n",
      "9/9 [==============================] - 2s 168ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1435 - factorized_top_k/top_5_categorical_accuracy: 0.3900 - factorized_top_k/top_10_categorical_accuracy: 0.4184 - factorized_top_k/top_50_categorical_accuracy: 0.4752 - factorized_top_k/top_100_categorical_accuracy: 0.4989 - loss: 14194.0637 - regularization_loss: 0.0000e+00 - total_loss: 14194.0637\n",
      "9/9 [==============================] - 2s 164ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1393 - factorized_top_k/top_5_categorical_accuracy: 0.3966 - factorized_top_k/top_10_categorical_accuracy: 0.4267 - factorized_top_k/top_50_categorical_accuracy: 0.4746 - factorized_top_k/top_100_categorical_accuracy: 0.5079 - loss: 14182.3442 - regularization_loss: 0.0000e+00 - total_loss: 14182.3442\n",
      "2/2 [==============================] - 0s 108ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1219 - factorized_top_k/top_5_categorical_accuracy: 0.3681 - factorized_top_k/top_10_categorical_accuracy: 0.3990 - factorized_top_k/top_50_categorical_accuracy: 0.4472 - factorized_top_k/top_100_categorical_accuracy: 0.4770 - loss: 12505.1901 - regularization_loss: 0.0000e+00 - total_loss: 12505.1901\n",
      "Top-100 accuracy (train): 0.51.\n",
      "Top-100 accuracy (test): 0.48.\n"
     ]
    }
   ],
   "source": [
    "model = MovielensModel(use_timestamps=True)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "model.fit(cached_train, epochs=3)\n",
    "\n",
    "train_accuracy = model.evaluate(\n",
    "    cached_train, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "test_accuracy = model.evaluate(\n",
    "    cached_test, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "\n",
    "print(f\"Top-100 accuracy (train): {train_accuracy:.2f}.\")\n",
    "print(f\"Top-100 accuracy (test): {test_accuracy:.2f}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hkjc-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
