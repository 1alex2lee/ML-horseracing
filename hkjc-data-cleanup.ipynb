{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexlee/Library/Python/3.8/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_columns (df, columns):\n",
    "    new_df = pd.DataFrame()\n",
    "    for c in columns:\n",
    "        if c in df.columns:\n",
    "            new_df[c] = df[c]\n",
    "        else:\n",
    "            new_df[c] = np.nan\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = os.path.join(\"data\",\"2_cleaned\",'horses')\n",
    "out_path = os.path.join(\"data\",\"3_extracted\")\n",
    "\n",
    "for file_name in [f for f in os.listdir(in_path) if not f.startswith(\".\")]:\n",
    "\n",
    "    # try:\n",
    "    #     df = pd.read_csv(os.path.join(out_path, file_name), index_col=0)\n",
    "    #     if 'jockey_age' in df.columns:\n",
    "    #         continue\n",
    "    # except:\n",
    "    #     pass\n",
    "\n",
    "    horse_df = pd.read_csv(os.path.join(in_path, file_name), index_col=0)\n",
    "    if 'horse_finish_time' not in horse_df.columns:\n",
    "        continue\n",
    "    for c in horse_df.columns:\n",
    "        horse_df[c] = horse_df[c].apply(lambda x: str(x).lower())\n",
    "    horse_df['finish_time'] = horse_df['horse_finish_time']\n",
    "    horse_df['race_date'] = pd.to_datetime(horse_df['race_date'], format='%Y/%m/%d', errors='coerce')\n",
    "    horse_df['race_index'] = horse_df['race_date'].apply(lambda x: x.strftime('%Y_')) + pd.to_numeric(horse_df['Race Index']).astype(int).astype(str)\n",
    "    horse_df.drop_duplicates('race_date', inplace=True)\n",
    "    horse_df = horse_df[horse_df['horse_finish_time'] != '--']\n",
    "    horse_df.reset_index(drop=True, inplace=True)\n",
    "    if 'Import Date' in horse_df.columns:\n",
    "        horse_df['Import Date'] = pd.to_datetime(horse_df['Import Date'], format='%d/%m/%Y', errors='coerce')\n",
    "        horse_df['days_since_import'] = (horse_df['race_date'] - horse_df['Import Date']).apply(lambda x: x.days)\n",
    "    else:\n",
    "        earliest_race_date = horse_df['race_date'].min()\n",
    "        horse_df['days_since_import'] = (horse_df['race_date'] - earliest_race_date).apply(lambda x: x.days + 177)\n",
    "    horse_df['horse_gear'] = (horse_df['Gear'] != '--').astype(int)\n",
    "    horse_df['total_stakes'] = horse_df['Total Stakes*'].apply(lambda x: x.replace('$','').replace(',',''))\n",
    "\n",
    "    jockey_age = []\n",
    "    jockey_nationality = []\n",
    "    jockey_wins = []\n",
    "    jockey_rides = []\n",
    "    jockey_stakes = []\n",
    "    jockey_same_race_wins = []\n",
    "\n",
    "    for idx, row in horse_df.iterrows():\n",
    "        jockey_file_path = os.path.join('data','1_scrape','jockeys',f'{row[\"Jockey\"]}.csv')\n",
    "        if not os.path.exists(jockey_file_path):\n",
    "            jockey_age.append(np.nan)\n",
    "            jockey_nationality.append(np.nan)\n",
    "            jockey_wins.append(np.nan)\n",
    "            jockey_rides.append(np.nan)\n",
    "            jockey_stakes.append(np.nan)\n",
    "            jockey_same_race_wins.append(np.nan)\n",
    "            continue\n",
    "        jockey_df = pd.read_csv(jockey_file_path, index_col=0)\n",
    "        try:\n",
    "            jockey_age.append(int(jockey_df['jockey_age'].unique()[0]) - (2023 - int(row['race_date'].year)))\n",
    "        except:\n",
    "            jockey_age.append(np.nan)\n",
    "        jockey_nationality.append(jockey_df['nationality'].unique()[0])\n",
    "        jockey_wins.append(jockey_df['no. of wins'].unique()[0])\n",
    "        jockey_rides.append(jockey_df['total rides'].unique()[0])\n",
    "        jockey_stakes.append(str(jockey_df['stakes won'].unique()[0]).replace('$','').replace(',','').strip())\n",
    "\n",
    "        race_distance = str(row[\"race_distance\"]).replace('.0','')\n",
    "        if 'sha tin' in row[\"race_location\"]:\n",
    "            try:\n",
    "                jockey_same_race_wins.append(jockey_df[f'{row[\"race_surface\"]}_{race_distance}_win'].unique()[0])\n",
    "            except:\n",
    "                jockey_same_race_wins.append(jockey_df[f'sha tin_all weather_{race_distance}_win'].unique()[0])\n",
    "        else:\n",
    "            jockey_same_race_wins.append(jockey_df[f'{row[\"race_location\"].replace(\"ch\",\"conghua\")}_{race_distance}_win'].unique()[0])\n",
    "\n",
    "    horse_df['jockey_age'] = jockey_age\n",
    "    horse_df['jockey_nationality'] = jockey_nationality\n",
    "    horse_df['jockey_wins'] = jockey_wins\n",
    "    horse_df['jockey_rides'] = jockey_rides\n",
    "    horse_df['jockey_stakes'] = jockey_stakes\n",
    "    horse_df['jockey_same_race_wins'] = jockey_same_race_wins\n",
    "\n",
    "    df = extract_columns(horse_df,['race_index','total_stakes','horse_weight','horse_handicap','horse_odds','horse_rating','horse_import_type','horse_sex','horse_colour',\n",
    "                'horse_age','horse_origin','horse_gear','days_since_import',\n",
    "                'draw',\n",
    "                'jockey_age','jockey_nationality','jockey_wins','jockey_rides','jockey_stakes','jockey_same_race_wins',\n",
    "                'race_location','race_class','race_going','race_distance','race_surface','race_course',\n",
    "                'finish_time','place'])\n",
    "\n",
    "    df.to_csv(os.path.join(out_path, file_name))\n",
    "    print(file_name, 'saved')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = os.path.join(\"data\",\"3_extracted\")\n",
    "\n",
    "entire_df = pd.DataFrame()\n",
    "\n",
    "for file_name in [f for f in os.listdir(in_path) if not f.startswith(\".\")]:\n",
    "\n",
    "    file = os.path.join(in_path, file_name)\n",
    "    current_race_df = pd.read_csv(file, index_col=0)\n",
    "\n",
    "    entire_df = pd.concat([entire_df, current_race_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(\"data\",\"4_races\")\n",
    "\n",
    "for race_index in entire_df['race_index'].unique():\n",
    "    df = entire_df[entire_df['race_index'] == race_index]\n",
    "    # if len(df.index) < 5:\n",
    "    #     continue\n",
    "    df.sort_values('place', inplace=True)\n",
    "\n",
    "    cols_to_rank = ['total_stakes','horse_weight','horse_handicap','horse_odds','horse_rating','days_since_import',\n",
    "        'jockey_age','jockey_rides','jockey_stakes','jockey_same_race_wins']\n",
    "\n",
    "    for c in cols_to_rank:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "        df[f'{c}_rank'] = df[c].rank(method='dense', ascending=False)\n",
    "\n",
    "    df.to_csv(os.path.join(out_path,f'{race_index}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = os.path.join(\"data\",\"4_races\")\n",
    "out_path = os.path.join(\"data\",\"5_ordinal_mean_tensor\")\n",
    "\n",
    "entire_df = pd.DataFrame()\n",
    "\n",
    "mean_std_dict = {}\n",
    "\n",
    "for file_name in [f for f in os.listdir(in_path) if not f.startswith(\".\")]:\n",
    "\n",
    "    file = os.path.join(in_path, file_name)\n",
    "    current_race_df = pd.read_csv(file, index_col=0)\n",
    "\n",
    "    entire_df = pd.concat([entire_df, current_race_df])\n",
    "\n",
    "entire_df['race_class'] = entire_df['race_class'].replace(['g1','g2','g3','3r','4r'],[1,2,3,3,4])\n",
    "\n",
    "ordinal_cols = ['horse_origin','horse_colour','horse_sex','horse_import_type',\n",
    "                'race_location','race_class','race_surface','race_course','race_going',\n",
    "                'jockey_nationality']\n",
    "\n",
    "# for c in entire_df.columns:\n",
    "#     print(c, entire_df[c].unique())\n",
    "\n",
    "for c in ordinal_cols:\n",
    "    ordinal_dict = {}\n",
    "    entire_df[c] = entire_df[c].astype(str)\n",
    "    for v in entire_df[c].unique():\n",
    "        if v in ['','nan']:\n",
    "            continue\n",
    "        ordinal_dict[v] = len(entire_df.loc[(entire_df[c] == v) & (entire_df['place'] == 1)])\n",
    "    ordinal_dict = {key: rank for rank, key in enumerate(sorted(ordinal_dict, key=ordinal_dict.get, reverse=True), 1)}\n",
    "\n",
    "    entire_df[c].replace(ordinal_dict, inplace=True)\n",
    "    ordinal_df = pd.DataFrame(ordinal_dict, index=[0])\n",
    "    ordinal_df.to_csv(os.path.join(out_path, 'ordinals', f'{c}_ordinal.csv'))\n",
    "\n",
    "for c in entire_df.columns:\n",
    "    if c == 'race_index':\n",
    "        continue\n",
    "    entire_df[c] = pd.to_numeric(entire_df[c], errors='coerce')\n",
    "\n",
    "    mean = entire_df[c].mean()\n",
    "    std = entire_df[c].std()\n",
    "\n",
    "    entire_df[c] = (entire_df[c] - mean) / std\n",
    "    entire_df[c] = entire_df[c].replace(np.nan, 0)\n",
    "    \n",
    "    mean_std_dict[c] = {'mean': mean, 'std': std}\n",
    "\n",
    "mean_std_df = pd.DataFrame(mean_std_dict)\n",
    "mean_std_df.to_csv(os.path.join(out_path, 'mean_std.csv'))\n",
    "\n",
    "x_df = entire_df.drop(['race_index','place','finish_time'], axis=1)\n",
    "\n",
    "# finish time in seconds\n",
    "y_df = entire_df['finish_time']\n",
    "x = x_df.to_numpy()\n",
    "y = y_df.to_numpy()\n",
    "x_tensor = torch.from_numpy(x)\n",
    "y_tensor = torch.from_numpy(y)\n",
    "torch.save(x_tensor, os.path.join(out_path, 'finish_time', \"x_tensor\"))\n",
    "torch.save(y_tensor, os.path.join(out_path, 'finish_time', \"y_tensor\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = os.path.join(\"data\",\"4_races\")\n",
    "out_path = os.path.join(\"data\",\"5_ordinal_mean_tensor\")\n",
    "\n",
    "for file_name in [f for f in os.listdir(in_path) if not f.startswith(\".\")]:\n",
    "    df = pd.read_csv(os.path.join(in_path, file_name), index_col=0)\n",
    "    df.drop('race_index', axis=1, inplace=True)\n",
    "\n",
    "    for ordinal_file in [f for f in os.listdir(os.path.join('data','5_ordinal_mean_tensor','ordinals')) if '.csv' in f]:\n",
    "        ordinal_dict = pd.read_csv(os.path.join('data','5_ordinal_mean_tensor','ordinals',ordinal_file), index_col=0).to_dict(orient='list')\n",
    "        for key in ordinal_dict:\n",
    "            ordinal_dict[key] = ordinal_dict[key][0]\n",
    "        c = ordinal_file.replace('_ordinal.csv','')\n",
    "        df[c].replace(ordinal_dict, inplace=True)\n",
    "\n",
    "    mean_std_df = pd.read_csv(os.path.join('data','5_ordinal_mean_tensor','mean_std.csv'), index_col=0)\n",
    "    for c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "        df[c] = (df[c] - mean_std_df.loc['mean', c]) / mean_std_df.loc['std', c]\n",
    "        df[c] = df[c].replace(np.nan, mean_std_df.loc['mean', c])\n",
    "\n",
    "    df.to_csv(os.path.join(out_path, 'evaluation', file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = os.path.join('data','5_ordinal_mean_tensor','evaluation')\n",
    "out_path = os.path.join('data','5_ordinal_mean_tensor')\n",
    "\n",
    "entire_df = pd.DataFrame()\n",
    "\n",
    "for file_name in [f for f in os.listdir(in_path) if not f.startswith(\".\")]:\n",
    "    df = pd.read_csv(os.path.join(in_path, file_name), index_col=0)\n",
    "\n",
    "    entire_df = pd.concat([entire_df, df])\n",
    "\n",
    "entire_df.to_csv(os.path.join(out_path, 'all_races.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "in_path = os.path.join(\"data\",\"5_ordinal_mean_tensor\")\n",
    "\n",
    "x_tensor = torch.load(os.path.join(in_path, 'finish_time', \"x_tensor\"))\n",
    "y_tensor = torch.load(os.path.join(in_path, 'finish_time', \"y_tensor\"))\n",
    "\n",
    "x_np = x_tensor.numpy()\n",
    "y_np = y_tensor.numpy()\n",
    "\n",
    "print(np.isnan(x_np).any())\n",
    "print(np.isnan(y_np).any())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
