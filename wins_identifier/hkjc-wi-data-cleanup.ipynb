{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, layers):\n",
    "        super(MLP, self).__init__()\n",
    "        modules = nn.ModuleList([nn.Flatten(), nn.Linear(input_size, layers[0]), nn.ReLU()])\n",
    "        for idx, size in enumerate(layers[:-1]):\n",
    "            modules.append(nn.Linear(size, layers[idx + 1]))\n",
    "            modules.append(nn.ReLU())\n",
    "        modules.append(nn.Linear(layers[-1], 1))\n",
    "        self.layers = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model (input_size, layers, file):\n",
    "    model_path = os.path.join('/Users/alexlee/My Drive/Colab Notebooks/HKJC-ML/model_configs/hkjc5', file)\n",
    "    \n",
    "    input_size = int(input_size)\n",
    "    layers = layers.strip('][').split(', ')\n",
    "    layers_int = []\n",
    "    for l in layers:\n",
    "        layers_int.append(int(l))\n",
    "    # print(input_size, layers_int)\n",
    "    # print(type(input_size), type(layers_int))\n",
    "    \n",
    "    device = (\n",
    "        \"cuda\"\n",
    "        if torch.cuda.is_available()\n",
    "        else \"mps\"\n",
    "        if torch.backends.mps.is_available()\n",
    "        else \"cpu\"\n",
    "    )\n",
    "    # print(f\"Using {device} device\")\n",
    "    model = MLP(input_size, layers_int).to(device)\n",
    "    # model = ConvNet(input_size, hidden_size, output_size).to(device)\n",
    "\n",
    "    model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
    "    model.eval()\n",
    "    # print(file, 'loaded')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_normalise (df, cols_to_keep):    \n",
    "    in_path = os.path.join('/Users/alexlee/Documents/Coding/HKJC-ML/hkjc5','data','5_ordinal_mean_tensor')\n",
    "    for ordinal_file in [f for f in os.listdir() if '.csv' in f]:\n",
    "        ordinal_dict = pd.read_csv(os.path.join(in_path,'ordinals',ordinal_file), index_col=0).to_dict(orient='list')\n",
    "        for key in ordinal_dict:\n",
    "            ordinal_dict[key] = ordinal_dict[key][0]\n",
    "\n",
    "        c = ordinal_file.replace('_ordinal.csv','')\n",
    "        df[c].replace(ordinal_dict, inplace=True)\n",
    "\n",
    "    cols_to_rank = [str(c).replace('_rank','') for c in cols_to_keep if 'rank' in c]\n",
    "\n",
    "    for c in cols_to_rank:\n",
    "        c = c.replace('\"','').replace(\"'\",'')\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "        df[f'{c}_rank'] = df[c].rank(method='dense', ascending=False)\n",
    "\n",
    "    mean_std_df = pd.read_csv(os.path.join(in_path,'mean_std.csv'), index_col=0)\n",
    "    for c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "        df[c] = (df[c] - mean_std_df.loc['mean', c]) / mean_std_df.loc['std', c]\n",
    "        df[c] = df[c].replace(np.nan, mean_std_df.loc['mean', c])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_func (x):\n",
    "    x = x.replace('.csv','')\n",
    "    race_no = x.split('_')[-1]\n",
    "    if len(str(race_no)) == 1:\n",
    "        race_no = '0' + str(race_no)\n",
    "    x = '_'.join(x.split('_')[:-1])\n",
    "    x += str(race_no)\n",
    "    return int(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate (cols_to_keep, layers, file):\n",
    "    model_wins_df = pd.DataFrame(columns=['race','win','trio_win'])\n",
    "\n",
    "    in_path = os.path.join('/Users/alexlee/Documents/Coding/HKJC-ML/hkjc5',\"data\",\"5_ordinal_mean_tensor\",'evaluation')\n",
    "\n",
    "    model = load_model(len(cols_to_keep), layers, file)\n",
    "    \n",
    "    for race_file_name in sorted([f for f in os.listdir(os.path.join(in_path)) if not f.startswith(\".\")], key=key_func):\n",
    "        race_df = pd.read_csv(os.path.join(in_path, race_file_name), index_col=0)\n",
    "\n",
    "        # ignore if race has less than 6 horses\n",
    "        if len(race_df.index) < 6:\n",
    "            continue\n",
    "\n",
    "        # win condition\n",
    "        win = False\n",
    "        trio_win = False\n",
    "\n",
    "        race_location = race_df['race_location'].unique()[0]\n",
    "        race_df = ordinal_normalise(race_df, cols_to_keep)\n",
    "        race_df.sort_values('place', inplace=True)\n",
    "        odds_df = race_df['horse_odds']\n",
    "        race_df.drop([\"place\"], axis=1, inplace=True)\n",
    "        race_df = pd.DataFrame(race_df, columns=cols_to_keep)\n",
    "        \n",
    "        # check for single win bet win\n",
    "        finish_times = []\n",
    "        for index, data in race_df.iterrows():\n",
    "            # if index == 0:\n",
    "            #     winning_bet_odds = (float(data[\"horse_odds\"]) * means_std.loc[\"std\", \"horse_odds\"]) + means_std.loc[\"mean\", \"horse_odds\"]\n",
    "            data = pd.to_numeric(data)\n",
    "            input_np = data.to_numpy()\n",
    "            input = torch.Tensor(input_np).unsqueeze(dim=0)\n",
    "            finish_times.append(model(input).detach().numpy()[0])\n",
    "        lost = False\n",
    "        for finish_time in finish_times[1:]:\n",
    "            if finish_times[0] > finish_time: # if first not shortest time\n",
    "                lost = True\n",
    "                break\n",
    "\n",
    "        # check if trio win\n",
    "        if all(max(finish_times[:3]) < t for t in finish_times[3:]):\n",
    "            trio_win = True\n",
    "\n",
    "        if not lost:\n",
    "            if not finish_times[0] in finish_times[1:]:\n",
    "                win = True\n",
    "\n",
    "        model_wins_df.loc[-1] = [race_file_name.replace('.csv',''), int(win), int(trio_win)]\n",
    "        model_wins_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return model_wins_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_race_info (df):\n",
    "    in_path = os.path.join('/Users/alexlee/Documents/Coding/HKJC-ML/hkjc5',\"data\",\"4_races\")\n",
    "\n",
    "    race_info_cols = ['race_location','race_class','race_going','race_distance','race_surface','race_course']\n",
    "    new_df_cols = ['race_location','race_class','race_going','race_distance','race_surface','race_course','win','trio_win']\n",
    "    new_dict = {}\n",
    "    for col in new_df_cols:\n",
    "        new_dict[col] = []\n",
    "    # new_df = pd.DataFrame(columns=new_df_cols)\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        race_df = pd.read_csv(os.path.join(in_path, f\"{row['race']}.csv\"), index_col=0)\n",
    "        for col in race_info_cols:\n",
    "            # print(race_df[col].unique()[0])\n",
    "            new_dict[col].append(race_df[col].unique()[0])\n",
    "            # new_df[col].loc[-1] = race_df[col].unique()[0]\n",
    "        new_dict['win'].append(row['win'])\n",
    "        new_dict['trio_win'].append(row['trio_win'])\n",
    "        # df_to_concat = pd.DataFrame(race_df, columns=race_info_cols)\n",
    "        # new_df = pd.concat([race_df, df_to_concat])\n",
    "        # new_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # new_df['win'] = df['win']\n",
    "    # new_df['trio_win'] = df['trio_win']\n",
    "        \n",
    "    new_df = pd.DataFrame(new_dict)\n",
    "\n",
    "    new_df.reset_index(drop=True, inplace=True)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "st model 2023_11_30_09_05_32_64_128_256_512_256_128_64_32_16_8_64_255_723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hv model 2024_01_03_21_04_64_128_256_256_128_64_32_16_8_4_64_313_00337\n"
     ]
    }
   ],
   "source": [
    "models_df = pd.read_csv(os.path.join('/Users/alexlee/Documents/Coding/HKJC-ML/hkjc5','data','5_ordinal_mean_tensor','model_names.csv'), index_col=0)\n",
    "out_path = os.path.join('data','1_analyse')\n",
    "\n",
    "models_df.sort_values('money_st', ascending=False, inplace=True)\n",
    "cols_to_keep = str(models_df.iloc[0]['cols_kept']).strip('][').replace('\"','').replace(\"'\",'').split(', ')\n",
    "layers = models_df.iloc[0]['layers']\n",
    "file = models_df.iloc[0]['file']\n",
    "\n",
    "model_data_path = os.path.join(out_path,f'{file}.csv')\n",
    "\n",
    "if not os.path.exists(model_data_path):\n",
    "    print('st model', file)\n",
    "\n",
    "    model_wins_df = evaluate (cols_to_keep, layers, file)\n",
    "    model_wins_df = get_race_info (model_wins_df)\n",
    "    model_wins_df.to_csv(model_data_path)\n",
    "\n",
    "models_df.sort_values('money_hv', ascending=False, inplace=True)\n",
    "cols_to_keep = str(models_df.iloc[0]['cols_kept']).strip('][').replace('\"','').replace(\"'\",'').split(', ')\n",
    "layers = models_df.iloc[0]['layers']\n",
    "file = models_df.iloc[0]['file']\n",
    "\n",
    "model_data_path = os.path.join(out_path,f'{file}.csv')\n",
    "\n",
    "if not os.path.exists(model_data_path):\n",
    "    print('hv model', file)\n",
    "\n",
    "    model_wins_df = evaluate (cols_to_keep, layers, file)\n",
    "    model_wins_df = get_race_info (model_wins_df)\n",
    "    model_wins_df.to_csv(model_data_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = os.path.join('data','1_analyse')\n",
    "oridnal_path = os.path.join('/Users/alexlee/Documents/Coding/HKJC-ML/hkjc5','data','5_ordinal_mean_tensor','ordinals')\n",
    "mean_std_path = os.path.join('data','2_ordinal_normalise','mean_std')\n",
    "out_path = os.path.join('data','2_ordinal_normalise')\n",
    "\n",
    "for file_name in [f for f in os.listdir(in_path) if 'csv' in f]:\n",
    "    df = pd.read_csv(os.path.join(in_path, file_name), index_col=0)\n",
    "\n",
    "    df['won'] = pd.to_numeric(df['win'] == 1)\n",
    "    df['not_won'] = pd.to_numeric(df['win'] == 0)\n",
    "\n",
    "    for ordinal_file in [f for f in os.listdir(oridnal_path) if '.csv' in f]:\n",
    "        c = ordinal_file.replace('_ordinal.csv','')\n",
    "        if not c in df.columns:\n",
    "            continue\n",
    "\n",
    "        ordinal_dict = pd.read_csv(os.path.join(oridnal_path,ordinal_file), index_col=0).to_dict(orient='list')\n",
    "        for key in ordinal_dict:\n",
    "            ordinal_dict[key] = ordinal_dict[key][0]\n",
    "        df[c].replace(ordinal_dict, inplace=True)\n",
    "\n",
    "    mean_std_dict = {}\n",
    "        \n",
    "    for c in df.columns:\n",
    "        if c in ['won','not_won']:\n",
    "            continue\n",
    "\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "        mean = df[c].mean()\n",
    "        std = df[c].std()\n",
    "\n",
    "        df[c] = (df[c] - mean) / std\n",
    "        df[c] = df[c].replace(np.nan, 0)\n",
    "        \n",
    "        mean_std_dict[c] = {'mean': mean, 'std': std}\n",
    "\n",
    "    mean_std_df = pd.DataFrame(mean_std_dict)\n",
    "    mean_std_df.to_csv(os.path.join(mean_std_path, f'{file_name.replace(\"csv\",\"\")}_mean_std.csv'))\n",
    "\n",
    "    df.to_csv(os.path.join(out_path, file_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
