{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, layers):\n",
    "        super(MLP, self).__init__()\n",
    "        modules = nn.ModuleList([nn.Flatten(), nn.Linear(input_size, layers[0]), nn.ReLU()])\n",
    "        for idx, size in enumerate(layers[:-1]):\n",
    "            modules.append(nn.Linear(size, layers[idx + 1]))\n",
    "            modules.append(nn.ReLU())\n",
    "        modules.append(nn.Linear(layers[-1], 1))\n",
    "        self.layers = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model (input_size, layers, file):\n",
    "    model_path = os.path.join('/Users/alexlee/My Drive/Colab Notebooks/HKJC-ML/hkjc5/model_configs/hkjc5', file)\n",
    "    \n",
    "    input_size = int(input_size)\n",
    "    # layers = layers.strip('][').split(', ')\n",
    "    layers = layers.strip('][').replace('\\n', ',').replace(' ',',').split(',')\n",
    "    layers = list(filter(None, layers))\n",
    "    \n",
    "    layers_int = []\n",
    "    for l in layers:\n",
    "        layers_int.append(int(l))\n",
    "    # print(input_size, layers_int)\n",
    "    # print(type(input_size), type(layers_int))\n",
    "    \n",
    "    device = (\n",
    "        \"cuda\"\n",
    "        if torch.cuda.is_available()\n",
    "        else \"mps\"\n",
    "        if torch.backends.mps.is_available()\n",
    "        else \"cpu\"\n",
    "    )\n",
    "    # print(f\"Using {device} device\")\n",
    "    model = MLP(input_size, layers_int).to(device)\n",
    "    # model = ConvNet(input_size, hidden_size, output_size).to(device)\n",
    "\n",
    "    model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
    "    model.eval()\n",
    "    print(file, 'loaded')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_df = pd.read_csv(os.path.join('data','5_ordinal_mean_tensor','model_names.csv'), index_col=0)\n",
    "models_df = pd.read_csv(os.path.join('/Users/alexlee/My Drive/Colab Notebooks/HKJC-ML/hkjc5','model_names_scored.csv'), index_col=0)\n",
    "\n",
    "# df = models_df\n",
    "# df = models_df[models_df['score'] < 65]\n",
    "# df.sort_values('money', ascending=False, inplace=True)\n",
    "# df = df.loc[df['file'] == '2023_11_14_10_26_32_64_128_256_512_256_128_64_32_16_8_4_64_448_0588']\n",
    "\n",
    "# models_df.sort_values('money_hv', ascending=False, inplace=True)\n",
    "# cols_to_keep = str(models_df.iloc[0]['cols_kept']).strip('][').replace('\"','').replace(\"'\",'').split(', ')\n",
    "# layers = models_df.iloc[0]['layers']\n",
    "# file = models_df.iloc[0]['file']\n",
    "\n",
    "# model = load_model(len(cols_to_keep), layers, file)\n",
    "\n",
    "# for idx, row in df.iterrows():\n",
    "#     if row['file'] != '2023_11_28_19_31_64_32_16_8_64_348_0261':\n",
    "#         continue\n",
    "#     cols_to_keep = str(row['cols_kept']).strip('][').replace('\"','').replace(\"'\",'').split(', ')\n",
    "#     layers = row['layers']\n",
    "#     file = row['file']\n",
    "\n",
    "#     model = load_model(len(cols_to_keep), layers, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict = torch.load(model_path, map_location=\"cpu\")\n",
    "# # Define the input and output sizes\n",
    "# input_size = 25\n",
    "# output_size = 1\n",
    "\n",
    "# model = MLP(input_size, output_size).to(device)\n",
    "# # model = ConvNet(input_size, hidden_size, output_size).to(device)\n",
    "\n",
    "# model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024_01_03_18_57_64_128_256_512_512_256_128_64_32_16_8_64_305_00334 loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024_01_28_1 [7, 9, 5, 1, 4, 2, 3, 10, 6, 8]\n",
      "2024_01_28_2 [6, 8, 10, 12, 13, 2, 4, 5, 7, 3, 1, 9, 11, 14]\n",
      "2024_01_28_3 [5, 1, 7, 14, 8, 9, 3, 2, 10, 6, 12, 4, 13, 11]\n",
      "2024_01_28_4 [2, 8, 13, 6, 5, 7, 9, 14, 11, 10, 12, 3, 4, 1]\n",
      "2024_01_28_5 [7, 4, 3, 1, 5, 10, 8, 9, 13, 14, 2, 12, 6, 11]\n",
      "2024_01_28_6 [1, 12, 8, 2, 6, 14, 7, 11, 5, 4, 9, 13, 3, 10]\n",
      "2024_01_28_7 [1, 7, 4, 9, 8, 5, 2, 3, 12, 10, 6, 13, 14, 11]\n",
      "2024_01_28_8 [5, 6, 2, 1, 4, 12, 10, 3, 8, 7, 9, 11, 13]\n",
      "2024_01_28_9 [2, 5, 6, 7, 14, 8, 13, 1, 12, 3, 11, 9, 4, 10]\n",
      "2024_01_28_10 [11, 1, 10, 6, 3, 2, 12, 7, 8, 9, 4, 14, 13, 5]\n"
     ]
    }
   ],
   "source": [
    "def key_func (x):\n",
    "    x = x.replace('.csv','')\n",
    "    race_no = x.split('_')[-1]\n",
    "    if len(str(race_no)) == 1:\n",
    "        race_no = '0' + str(race_no)\n",
    "    x = '_'.join(x.split('_')[:-1])\n",
    "    x += str(race_no)\n",
    "    return int(x)\n",
    "\n",
    "in_path = os.path.join('data','6_prediction')\n",
    "\n",
    "# for file_name in sorted([f for f in os.listdir(in_path) if '.csv' in f], key=lambda x: int(x.split('_')[-1].replace('.csv',''))):\n",
    "for file_name in sorted([f for f in os.listdir(in_path) if '.csv' in f], key=key_func):\n",
    "    df = pd.read_csv(os.path.join(in_path, file_name), index_col=0)\n",
    "    race_location = df['race_location'].unique()[0]\n",
    "\n",
    "    if race_location == 'happy valley':\n",
    "        models_df.sort_values('money_hv', ascending=False, inplace=True)\n",
    "        cols_to_keep = str(models_df.iloc[0]['cols_kept']).strip('][').replace('\"','').replace(\"'\",'').split(', ')\n",
    "        layers = models_df.iloc[0]['layers']\n",
    "        file = models_df.iloc[0]['file']\n",
    "\n",
    "    elif race_location == 'sha tin':\n",
    "        models_df.sort_values('money_st', ascending=False, inplace=True)\n",
    "        cols_to_keep = str(models_df.iloc[1]['cols_kept']).strip('][').replace('\"','').replace(\"'\",'').split(', ')\n",
    "        layers = models_df.iloc[1]['layers']\n",
    "        file = models_df.iloc[1]['file']\n",
    "        \n",
    "    model = load_model(len(cols_to_keep), layers, file)\n",
    "    break\n",
    "\n",
    "for file_name in sorted([f for f in os.listdir(in_path) if '.csv' in f], key=key_func):\n",
    "\n",
    "    df = pd.read_csv(os.path.join(in_path, file_name), index_col=0)\n",
    "    if 'place' in df.columns:\n",
    "        df.drop('place', axis=1, inplace=True)\n",
    "\n",
    "    for ordinal_file in [f for f in os.listdir(os.path.join('data','5_ordinal_mean_tensor','ordinals')) if '.csv' in f]:\n",
    "        ordinal_dict = pd.read_csv(os.path.join('data','5_ordinal_mean_tensor','ordinals',ordinal_file), index_col=0).to_dict(orient='list')\n",
    "        for key in ordinal_dict:\n",
    "            ordinal_dict[key] = ordinal_dict[key][0]\n",
    "\n",
    "        c = ordinal_file.replace('_ordinal.csv','')\n",
    "        df[c].replace(ordinal_dict, inplace=True)\n",
    "\n",
    "    cols_to_rank = [str(c).replace('_rank','') for c in cols_to_keep if 'rank' in c]\n",
    "\n",
    "    for c in cols_to_rank:\n",
    "        c = c.replace('\"','').replace(\"'\",'')\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "        df[f'{c}_rank'] = df[c].rank(method='dense', ascending=False)\n",
    "\n",
    "    mean_std_df = pd.read_csv(os.path.join('data','5_ordinal_mean_tensor','mean_std.csv'), index_col=0)\n",
    "    for c in df.columns:\n",
    "        if c not in cols_to_keep:\n",
    "            df.drop(c, axis=1, inplace=True)\n",
    "            continue\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "        df[c] = (df[c] - mean_std_df.loc['mean', c]) / mean_std_df.loc['std', c]\n",
    "        df[c] = df[c].replace(np.nan, mean_std_df.loc['mean', c])\n",
    "\n",
    "    predicted_race = {} \n",
    "    for index, row in df.iterrows():\n",
    "        input_np = row.to_numpy()\n",
    "        input = torch.Tensor(input_np).unsqueeze(dim=0)\n",
    "        predicted_race[index + 1] = (model(input).detach().numpy()[0])[0]\n",
    "    \n",
    "    pd.DataFrame(predicted_race, index=[0]).transpose().to_csv(os.path.join('data','7_predicted',file_name))\n",
    "\n",
    "    print(file_name.replace('.csv',''), [k for k, v in sorted(predicted_race.items(), key=lambda item: item[1])])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
